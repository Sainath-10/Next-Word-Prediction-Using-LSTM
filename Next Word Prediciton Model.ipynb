{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b315e4-d828-4609-b62d-a4b263167ae4",
   "metadata": {},
   "source": [
    "# `Project Overview`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d61717-6ab2-4a8d-bf5b-521b8711ac1e",
   "metadata": {},
   "source": [
    "This project builds a Next Word Prediction model using an LSTM neural network trained on Shakespeareâ€™s Hamlet text. The model learns language patterns, word relationships, and context by processing sequences of words and predicting the most likely next word. The dataset is taken from the NLTK Gutenberg corpus and saved locally for training. An embedding layer converts words into vector representations, stacked LSTM layers learn long-term dependencies in the text, and a softmax output layer predicts the next word from the vocabulary. This project demonstrates how deep learning can be used for language modeling and text generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c89b4b-9d37-4f46-919e-1eeed8a4cde6",
   "metadata": {},
   "source": [
    "# `Importing Libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282c2ba2-4a90-451c-82fe-47c559444c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.10.0\n",
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs detected:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa9a6f7-db9d-48ce-8aeb-5c2ea0f4595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\saina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "\n",
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "with open('data_hamlet.txt','w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff6f278-d466-4d3d-9e75-0503ce507fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fc2c8e-3d8b-451c-be16-538ecb563fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_hamlet.txt','r') as file:\n",
    "    data = file.read().lower()   # This is String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9933c32-7d7e-45f3-9245-89faff85605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text (Giving Index to Each Word)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "with open('Tokenizer_File.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86517e18-7698-4d8d-b5f1-395b5e0b5c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(tokenizer.word_index)  # Word -> Index (Key Value Pairs)\n",
    "total_n_words = len(tokenizer.word_index) + 1\n",
    "total_n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23a66cd7-672e-4ecf-814b-d09e8c2e426c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 687],\n",
       " [1, 687, 4],\n",
       " [1, 687, 4, 45],\n",
       " [1, 687, 4, 45, 41],\n",
       " [1, 687, 4, 45, 41, 1886],\n",
       " [1, 687, 4, 45, 41, 1886, 1887],\n",
       " [1, 687, 4, 45, 41, 1886, 1887, 1888],\n",
       " [1180, 1889],\n",
       " [1180, 1889, 1890],\n",
       " [1180, 1889, 1890, 1891],\n",
       " [57, 407],\n",
       " [57, 407, 2],\n",
       " [57, 407, 2, 1181],\n",
       " [57, 407, 2, 1181, 177],\n",
       " [57, 407, 2, 1181, 177, 1892],\n",
       " [407, 1182],\n",
       " [407, 1182, 63],\n",
       " [408, 162],\n",
       " [408, 162, 377],\n",
       " [408, 162, 377, 21]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create n-gram input sequences\n",
    "sequences = []\n",
    "\n",
    "for sentence in data.split(\"\\n\"):\n",
    "    tokens = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokens)):\n",
    "        sequence = tokens[:i + 1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "sequences[:20]\n",
    "\n",
    "# Here at Input / Output Division \n",
    "# The Last Item Will Be removed and Assigned in y\n",
    "\n",
    "# [1]                      predict 687\n",
    "# [1, 687]                 predict 4\n",
    "# [1, 687, 4]              predict 45\n",
    "# [1, 687, 4, 45]          predict 41\n",
    "# [1, 687, 4, 45, 41]      predict 1886\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1dee3e-95cb-4c4b-8790-814000f80182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,  687],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,  687,    4],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,  687,    4,   45],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    1,  687,    4,   45,   41],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    1,  687,    4,   45,   41, 1886],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    1,  687,    4,   45,   41, 1886, 1887],\n",
       "       [   0,    0,    0,    0,    0,    0,    1,  687,    4,   45,   41, 1886, 1887, 1888],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1180, 1889],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1180, 1889, 1890],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 1180, 1889, 1890, 1891],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   57,  407],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   57,  407,    2],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   57,  407,    2, 1181],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,   57,  407,    2, 1181,  177],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,   57,  407,    2, 1181,  177, 1892],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  407, 1182],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  407, 1182,   63],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  408,  162],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  408,  162,  377],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  408,  162,  377,   21]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad Sequences\n",
    "max_len_sequences =max([len(x) for x in sequences])\n",
    "\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_len_sequences, padding='pre'))\n",
    "sequences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1be7b5a0-a256-46fa-a482-8c19bcb8974d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25732, 13),\n",
       " (25732,),\n",
       " array([[   0,    0,    0, ...,    0,    0,    1],\n",
       "        [   0,    0,    0, ...,    0,    1,  687],\n",
       "        [   0,    0,    0, ...,    1,  687,    4],\n",
       "        ...,\n",
       "        [   0,    0,    0, ...,  687,    4,   45],\n",
       "        [   0,    0,    0, ...,    4,   45, 1047],\n",
       "        [   0,    0,    0, ...,   45, 1047,    4]]),\n",
       " array([ 687,    4,   45, ..., 1047,    4,  193]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]\n",
    "\n",
    "X.shape, y.shape, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175a6a93-43c1-4530-8fe2-50b98c66f025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25732, 4818),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.keras.utils.to_categorical(y, num_classes = total_n_words)\n",
    "y.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7e01d1-08a1-41bd-a4e5-4f4b0cdaf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960cb38-dd15-4928-92ca-246d6ec13e81",
   "metadata": {},
   "source": [
    "# `Training Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9766fecf-9b9b-48d2-8b36-a48e1c8932ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 13, 150)           150600    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 150)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,219,418\n",
      "Trainable params: 1,219,418\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim = total_n_words, output_dim = 100, input_length = max_len_sequences - 1),\n",
    "    LSTM(150, return_sequences = True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dense(units = total_n_words, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dd734b6-c054-40aa-94fb-cfa623a0d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "644/644 [==============================] - 25s 28ms/step - loss: 6.9087 - accuracy: 0.0334 - val_loss: 6.7223 - val_accuracy: 0.0334\n",
      "Epoch 2/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.4791 - accuracy: 0.0394 - val_loss: 6.8001 - val_accuracy: 0.0394\n",
      "Epoch 3/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.3361 - accuracy: 0.0471 - val_loss: 6.8314 - val_accuracy: 0.0480\n",
      "Epoch 4/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.1798 - accuracy: 0.0522 - val_loss: 6.8644 - val_accuracy: 0.0521\n",
      "Epoch 5/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.0331 - accuracy: 0.0570 - val_loss: 6.8938 - val_accuracy: 0.0573\n",
      "Epoch 6/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.8727 - accuracy: 0.0670 - val_loss: 6.9500 - val_accuracy: 0.0626\n",
      "Epoch 7/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.7281 - accuracy: 0.0748 - val_loss: 7.0054 - val_accuracy: 0.0701\n",
      "Epoch 8/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.5958 - accuracy: 0.0834 - val_loss: 7.0950 - val_accuracy: 0.0696\n",
      "Epoch 9/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.4742 - accuracy: 0.0895 - val_loss: 7.1250 - val_accuracy: 0.0696\n",
      "Epoch 10/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.3507 - accuracy: 0.0953 - val_loss: 7.2933 - val_accuracy: 0.0762\n",
      "Epoch 11/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.2344 - accuracy: 0.0996 - val_loss: 7.3238 - val_accuracy: 0.0754\n",
      "Epoch 12/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.1259 - accuracy: 0.1067 - val_loss: 7.4278 - val_accuracy: 0.0762\n",
      "Epoch 13/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.0165 - accuracy: 0.1101 - val_loss: 7.5517 - val_accuracy: 0.0731\n",
      "Epoch 14/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.9083 - accuracy: 0.1166 - val_loss: 7.6304 - val_accuracy: 0.0729\n",
      "Epoch 15/150\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 4.8012 - accuracy: 0.1203 - val_loss: 7.7615 - val_accuracy: 0.0740\n",
      "Epoch 16/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.6969 - accuracy: 0.1250 - val_loss: 7.8812 - val_accuracy: 0.0738\n",
      "Epoch 17/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.5910 - accuracy: 0.1308 - val_loss: 8.0169 - val_accuracy: 0.0740\n",
      "Epoch 18/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.4886 - accuracy: 0.1366 - val_loss: 8.1533 - val_accuracy: 0.0760\n",
      "Epoch 19/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.3887 - accuracy: 0.1425 - val_loss: 8.2729 - val_accuracy: 0.0727\n",
      "Epoch 20/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.2933 - accuracy: 0.1501 - val_loss: 8.4226 - val_accuracy: 0.0732\n",
      "Epoch 21/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.1994 - accuracy: 0.1593 - val_loss: 8.5661 - val_accuracy: 0.0721\n",
      "Epoch 22/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.1098 - accuracy: 0.1709 - val_loss: 8.7001 - val_accuracy: 0.0721\n",
      "Epoch 23/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.0179 - accuracy: 0.1817 - val_loss: 8.8322 - val_accuracy: 0.0711\n",
      "Epoch 24/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.9377 - accuracy: 0.1944 - val_loss: 8.9561 - val_accuracy: 0.0688\n",
      "Epoch 25/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.8570 - accuracy: 0.2065 - val_loss: 9.0770 - val_accuracy: 0.0701\n",
      "Epoch 26/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.7837 - accuracy: 0.2207 - val_loss: 9.2327 - val_accuracy: 0.0664\n",
      "Epoch 27/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.7152 - accuracy: 0.2283 - val_loss: 9.3462 - val_accuracy: 0.0678\n",
      "Epoch 28/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.6442 - accuracy: 0.2434 - val_loss: 9.4442 - val_accuracy: 0.0655\n",
      "Epoch 29/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.5772 - accuracy: 0.2532 - val_loss: 9.5988 - val_accuracy: 0.0663\n",
      "Epoch 30/150\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.5156 - accuracy: 0.2633 - val_loss: 9.6914 - val_accuracy: 0.0651\n",
      "Epoch 31/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 3.4614 - accuracy: 0.2741 - val_loss: 9.7666 - val_accuracy: 0.0661\n",
      "Epoch 32/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 3.3947 - accuracy: 0.2839 - val_loss: 9.8768 - val_accuracy: 0.0649\n",
      "Epoch 33/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 3.3379 - accuracy: 0.2946 - val_loss: 9.9965 - val_accuracy: 0.0633\n",
      "Epoch 34/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 3.2902 - accuracy: 0.3008 - val_loss: 10.0643 - val_accuracy: 0.0653\n",
      "Epoch 35/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 3.2378 - accuracy: 0.3086 - val_loss: 10.1866 - val_accuracy: 0.0653\n",
      "Epoch 36/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 3.1868 - accuracy: 0.3172 - val_loss: 10.2896 - val_accuracy: 0.0664\n",
      "Epoch 37/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 3.1355 - accuracy: 0.3295 - val_loss: 10.3624 - val_accuracy: 0.0668\n",
      "Epoch 38/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 3.0905 - accuracy: 0.3369 - val_loss: 10.4702 - val_accuracy: 0.0639\n",
      "Epoch 39/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 3.0444 - accuracy: 0.3418 - val_loss: 10.5380 - val_accuracy: 0.0633\n",
      "Epoch 40/150\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 3.0010 - accuracy: 0.3538 - val_loss: 10.6058 - val_accuracy: 0.0635\n",
      "Epoch 41/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 2.9544 - accuracy: 0.3627 - val_loss: 10.7279 - val_accuracy: 0.0670\n",
      "Epoch 42/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.9188 - accuracy: 0.3695 - val_loss: 10.8026 - val_accuracy: 0.0618\n",
      "Epoch 43/150\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.8747 - accuracy: 0.3802 - val_loss: 10.9057 - val_accuracy: 0.0618\n",
      "Epoch 44/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 2.8312 - accuracy: 0.3824 - val_loss: 10.9261 - val_accuracy: 0.0624\n",
      "Epoch 45/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 2.7976 - accuracy: 0.3910 - val_loss: 11.0406 - val_accuracy: 0.0610\n",
      "Epoch 46/150\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 2.7529 - accuracy: 0.3975 - val_loss: 11.0984 - val_accuracy: 0.0626\n",
      "Epoch 47/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 2.7201 - accuracy: 0.4050 - val_loss: 11.2046 - val_accuracy: 0.0629\n",
      "Epoch 48/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 2.6814 - accuracy: 0.4106 - val_loss: 11.2513 - val_accuracy: 0.0626\n",
      "Epoch 49/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 2.6457 - accuracy: 0.4178 - val_loss: 11.3295 - val_accuracy: 0.0606\n",
      "Epoch 50/150\n",
      "644/644 [==============================] - 11s 16ms/step - loss: 2.6144 - accuracy: 0.4254 - val_loss: 11.4110 - val_accuracy: 0.0624\n",
      "Epoch 51/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.5778 - accuracy: 0.4354 - val_loss: 11.4734 - val_accuracy: 0.0647\n",
      "Epoch 52/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 2.5491 - accuracy: 0.4386 - val_loss: 11.5521 - val_accuracy: 0.0657\n",
      "Epoch 53/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 2.5100 - accuracy: 0.4477 - val_loss: 11.6364 - val_accuracy: 0.0622\n",
      "Epoch 54/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 2.4760 - accuracy: 0.4483 - val_loss: 11.6837 - val_accuracy: 0.0614\n",
      "Epoch 55/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 2.4508 - accuracy: 0.4582 - val_loss: 11.7559 - val_accuracy: 0.0629\n",
      "Epoch 56/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 2.4233 - accuracy: 0.4627 - val_loss: 11.7989 - val_accuracy: 0.0629\n",
      "Epoch 57/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 2.3828 - accuracy: 0.4716 - val_loss: 11.8810 - val_accuracy: 0.0606\n",
      "Epoch 58/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 2.3565 - accuracy: 0.4762 - val_loss: 11.9387 - val_accuracy: 0.0593\n",
      "Epoch 59/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 2.3302 - accuracy: 0.4797 - val_loss: 12.0284 - val_accuracy: 0.0573\n",
      "Epoch 60/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 2.2936 - accuracy: 0.4908 - val_loss: 12.0363 - val_accuracy: 0.0608\n",
      "Epoch 61/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 2.2750 - accuracy: 0.4914 - val_loss: 12.1430 - val_accuracy: 0.0589\n",
      "Epoch 62/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 2.2401 - accuracy: 0.5014 - val_loss: 12.1967 - val_accuracy: 0.0606\n",
      "Epoch 63/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 2.2175 - accuracy: 0.5026 - val_loss: 12.2739 - val_accuracy: 0.0608\n",
      "Epoch 64/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 2.1888 - accuracy: 0.5085 - val_loss: 12.3027 - val_accuracy: 0.0608\n",
      "Epoch 65/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 2.1596 - accuracy: 0.5183 - val_loss: 12.3889 - val_accuracy: 0.0610\n",
      "Epoch 66/150\n",
      "644/644 [==============================] - 13s 19ms/step - loss: 2.1366 - accuracy: 0.5206 - val_loss: 12.4072 - val_accuracy: 0.0614\n",
      "Epoch 67/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 2.1128 - accuracy: 0.5256 - val_loss: 12.4684 - val_accuracy: 0.0591\n",
      "Epoch 68/150\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 2.0883 - accuracy: 0.5292 - val_loss: 12.5256 - val_accuracy: 0.0571\n",
      "Epoch 69/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 2.0620 - accuracy: 0.5373 - val_loss: 12.5999 - val_accuracy: 0.0585\n",
      "Epoch 70/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 2.0360 - accuracy: 0.5428 - val_loss: 12.6747 - val_accuracy: 0.0565\n",
      "Epoch 71/150\n",
      "644/644 [==============================] - 13s 19ms/step - loss: 2.0167 - accuracy: 0.5436 - val_loss: 12.7172 - val_accuracy: 0.0563\n",
      "Epoch 72/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.9901 - accuracy: 0.5503 - val_loss: 12.8108 - val_accuracy: 0.0569\n",
      "Epoch 73/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.9657 - accuracy: 0.5590 - val_loss: 12.8455 - val_accuracy: 0.0581\n",
      "Epoch 74/150\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 1.9436 - accuracy: 0.5601 - val_loss: 12.8796 - val_accuracy: 0.0585\n",
      "Epoch 75/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.9166 - accuracy: 0.5651 - val_loss: 12.9701 - val_accuracy: 0.0602\n",
      "Epoch 76/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.8976 - accuracy: 0.5706 - val_loss: 13.0002 - val_accuracy: 0.0585\n",
      "Epoch 77/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.8812 - accuracy: 0.5738 - val_loss: 13.0409 - val_accuracy: 0.0579\n",
      "Epoch 78/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.8598 - accuracy: 0.5791 - val_loss: 13.0900 - val_accuracy: 0.0604\n",
      "Epoch 79/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.8460 - accuracy: 0.5832 - val_loss: 13.1645 - val_accuracy: 0.0606\n",
      "Epoch 80/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.8180 - accuracy: 0.5852 - val_loss: 13.1764 - val_accuracy: 0.0577\n",
      "Epoch 81/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.7917 - accuracy: 0.5921 - val_loss: 13.2519 - val_accuracy: 0.0596\n",
      "Epoch 82/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.7768 - accuracy: 0.5980 - val_loss: 13.3359 - val_accuracy: 0.0569\n",
      "Epoch 83/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.7616 - accuracy: 0.5992 - val_loss: 13.3488 - val_accuracy: 0.0596\n",
      "Epoch 84/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.7442 - accuracy: 0.6044 - val_loss: 13.4346 - val_accuracy: 0.0554\n",
      "Epoch 85/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.7208 - accuracy: 0.6100 - val_loss: 13.4296 - val_accuracy: 0.0569\n",
      "Epoch 86/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.7088 - accuracy: 0.6082 - val_loss: 13.5015 - val_accuracy: 0.0579\n",
      "Epoch 87/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.6921 - accuracy: 0.6179 - val_loss: 13.5356 - val_accuracy: 0.0542\n",
      "Epoch 88/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.6725 - accuracy: 0.6176 - val_loss: 13.5548 - val_accuracy: 0.0565\n",
      "Epoch 89/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.6553 - accuracy: 0.6208 - val_loss: 13.6915 - val_accuracy: 0.0565\n",
      "Epoch 90/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 1.6333 - accuracy: 0.6297 - val_loss: 13.7111 - val_accuracy: 0.0544\n",
      "Epoch 91/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.6170 - accuracy: 0.6316 - val_loss: 13.7648 - val_accuracy: 0.0560\n",
      "Epoch 92/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.6094 - accuracy: 0.6284 - val_loss: 13.7941 - val_accuracy: 0.0546\n",
      "Epoch 93/150\n",
      "644/644 [==============================] - 13s 19ms/step - loss: 1.5878 - accuracy: 0.6365 - val_loss: 13.8480 - val_accuracy: 0.0563\n",
      "Epoch 94/150\n",
      "644/644 [==============================] - 13s 19ms/step - loss: 1.5790 - accuracy: 0.6376 - val_loss: 13.9153 - val_accuracy: 0.0536\n",
      "Epoch 95/150\n",
      "644/644 [==============================] - 10s 15ms/step - loss: 1.5540 - accuracy: 0.6400 - val_loss: 13.9514 - val_accuracy: 0.0556\n",
      "Epoch 96/150\n",
      "644/644 [==============================] - 10s 16ms/step - loss: 1.5433 - accuracy: 0.6478 - val_loss: 13.9846 - val_accuracy: 0.0569\n",
      "Epoch 97/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.5246 - accuracy: 0.6490 - val_loss: 13.9884 - val_accuracy: 0.0614\n",
      "Epoch 98/150\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 1.5106 - accuracy: 0.6553 - val_loss: 14.0596 - val_accuracy: 0.0569\n",
      "Epoch 99/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.4956 - accuracy: 0.6564 - val_loss: 14.1339 - val_accuracy: 0.0536\n",
      "Epoch 100/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.4772 - accuracy: 0.6598 - val_loss: 14.1410 - val_accuracy: 0.0550\n",
      "Epoch 101/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.4667 - accuracy: 0.6640 - val_loss: 14.1892 - val_accuracy: 0.0530\n",
      "Epoch 102/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.4591 - accuracy: 0.6619 - val_loss: 14.2305 - val_accuracy: 0.0548\n",
      "Epoch 103/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.4477 - accuracy: 0.6649 - val_loss: 14.3040 - val_accuracy: 0.0558\n",
      "Epoch 104/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.4277 - accuracy: 0.6711 - val_loss: 14.3389 - val_accuracy: 0.0536\n",
      "Epoch 105/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.4178 - accuracy: 0.6713 - val_loss: 14.3711 - val_accuracy: 0.0556\n",
      "Epoch 106/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.4001 - accuracy: 0.6750 - val_loss: 14.4005 - val_accuracy: 0.0554\n",
      "Epoch 107/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.3897 - accuracy: 0.6789 - val_loss: 14.4493 - val_accuracy: 0.0528\n",
      "Epoch 108/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.3826 - accuracy: 0.6787 - val_loss: 14.4803 - val_accuracy: 0.0540\n",
      "Epoch 109/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 1.3710 - accuracy: 0.6839 - val_loss: 14.5098 - val_accuracy: 0.0536\n",
      "Epoch 110/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.3608 - accuracy: 0.6832 - val_loss: 14.5202 - val_accuracy: 0.0542\n",
      "Epoch 111/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 1.3445 - accuracy: 0.6880 - val_loss: 14.5529 - val_accuracy: 0.0548\n",
      "Epoch 112/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.3283 - accuracy: 0.6909 - val_loss: 14.5587 - val_accuracy: 0.0542\n",
      "Epoch 113/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.3330 - accuracy: 0.6903 - val_loss: 14.6949 - val_accuracy: 0.0521\n",
      "Epoch 114/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.3100 - accuracy: 0.6965 - val_loss: 14.7023 - val_accuracy: 0.0532\n",
      "Epoch 115/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.3041 - accuracy: 0.6958 - val_loss: 14.7471 - val_accuracy: 0.0528\n",
      "Epoch 116/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.2928 - accuracy: 0.6966 - val_loss: 14.7787 - val_accuracy: 0.0540\n",
      "Epoch 117/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.2775 - accuracy: 0.7045 - val_loss: 14.8148 - val_accuracy: 0.0521\n",
      "Epoch 118/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.2629 - accuracy: 0.7062 - val_loss: 14.8784 - val_accuracy: 0.0517\n",
      "Epoch 119/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.2529 - accuracy: 0.7072 - val_loss: 14.8971 - val_accuracy: 0.0530\n",
      "Epoch 120/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.2485 - accuracy: 0.7103 - val_loss: 14.9207 - val_accuracy: 0.0492\n",
      "Epoch 121/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.2376 - accuracy: 0.7111 - val_loss: 14.9775 - val_accuracy: 0.0517\n",
      "Epoch 122/150\n",
      "644/644 [==============================] - 11s 18ms/step - loss: 1.2321 - accuracy: 0.7119 - val_loss: 15.0029 - val_accuracy: 0.0509\n",
      "Epoch 123/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.2177 - accuracy: 0.7156 - val_loss: 15.0863 - val_accuracy: 0.0530\n",
      "Epoch 124/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.2088 - accuracy: 0.7173 - val_loss: 15.1107 - val_accuracy: 0.0519\n",
      "Epoch 125/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.1973 - accuracy: 0.7205 - val_loss: 15.1079 - val_accuracy: 0.0532\n",
      "Epoch 126/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.1900 - accuracy: 0.7203 - val_loss: 15.1808 - val_accuracy: 0.0488\n",
      "Epoch 127/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.1790 - accuracy: 0.7234 - val_loss: 15.1648 - val_accuracy: 0.0513\n",
      "Epoch 128/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.1726 - accuracy: 0.7255 - val_loss: 15.2144 - val_accuracy: 0.0503\n",
      "Epoch 129/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.1621 - accuracy: 0.7253 - val_loss: 15.2165 - val_accuracy: 0.0521\n",
      "Epoch 130/150\n",
      "644/644 [==============================] - 13s 21ms/step - loss: 1.1547 - accuracy: 0.7313 - val_loss: 15.3237 - val_accuracy: 0.0528\n",
      "Epoch 131/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.1504 - accuracy: 0.7279 - val_loss: 15.3286 - val_accuracy: 0.0513\n",
      "Epoch 132/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.1449 - accuracy: 0.7316 - val_loss: 15.3709 - val_accuracy: 0.0515\n",
      "Epoch 133/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.1313 - accuracy: 0.7344 - val_loss: 15.3703 - val_accuracy: 0.0486\n",
      "Epoch 134/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.1167 - accuracy: 0.7417 - val_loss: 15.3786 - val_accuracy: 0.0507\n",
      "Epoch 135/150\n",
      "644/644 [==============================] - 11s 17ms/step - loss: 1.1143 - accuracy: 0.7373 - val_loss: 15.4424 - val_accuracy: 0.0544\n",
      "Epoch 136/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.1144 - accuracy: 0.7363 - val_loss: 15.4929 - val_accuracy: 0.0525\n",
      "Epoch 137/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.1064 - accuracy: 0.7420 - val_loss: 15.5310 - val_accuracy: 0.0501\n",
      "Epoch 138/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.0903 - accuracy: 0.7391 - val_loss: 15.5677 - val_accuracy: 0.0503\n",
      "Epoch 139/150\n",
      "644/644 [==============================] - 12s 19ms/step - loss: 1.0883 - accuracy: 0.7443 - val_loss: 15.5619 - val_accuracy: 0.0495\n",
      "Epoch 140/150\n",
      "644/644 [==============================] - 12s 18ms/step - loss: 1.0808 - accuracy: 0.7422 - val_loss: 15.6368 - val_accuracy: 0.0505\n",
      "Epoch 141/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.0744 - accuracy: 0.7466 - val_loss: 15.6960 - val_accuracy: 0.0468\n",
      "Epoch 142/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.0629 - accuracy: 0.7476 - val_loss: 15.7300 - val_accuracy: 0.0486\n",
      "Epoch 143/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.0679 - accuracy: 0.7457 - val_loss: 15.7171 - val_accuracy: 0.0521\n",
      "Epoch 144/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.0516 - accuracy: 0.7501 - val_loss: 15.7371 - val_accuracy: 0.0474\n",
      "Epoch 145/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.0403 - accuracy: 0.7524 - val_loss: 15.8098 - val_accuracy: 0.0523\n",
      "Epoch 146/150\n",
      "644/644 [==============================] - 14s 21ms/step - loss: 1.0399 - accuracy: 0.7516 - val_loss: 15.8236 - val_accuracy: 0.0497\n",
      "Epoch 147/150\n",
      "644/644 [==============================] - 14s 22ms/step - loss: 1.0346 - accuracy: 0.7541 - val_loss: 15.8655 - val_accuracy: 0.0493\n",
      "Epoch 148/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.0239 - accuracy: 0.7578 - val_loss: 15.8551 - val_accuracy: 0.0509\n",
      "Epoch 149/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.0195 - accuracy: 0.7583 - val_loss: 15.8636 - val_accuracy: 0.0495\n",
      "Epoch 150/150\n",
      "644/644 [==============================] - 13s 20ms/step - loss: 1.0196 - accuracy: 0.7575 - val_loss: 15.9277 - val_accuracy: 0.0482\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "LSTM_model_history = model.fit(X_train, y_train,\n",
    "                               epochs = 150, \n",
    "                               validation_data=(X_test,y_test),\n",
    "                               verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f1d4688-f521-47a7-8d01-06afc4d6c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Model\n",
    "model.save(\"next_word_predicter_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d43d79-6166-42ec-84f7-2765d98f1773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv_1]",
   "language": "python",
   "name": "conda-env-venv_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
